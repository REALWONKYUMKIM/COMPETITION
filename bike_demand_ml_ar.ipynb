{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d36fd9b-8277-46dd-ab5d-3563dcc739b7",
   "metadata": {},
   "source": [
    "<font size=6><b>Bike Sharing Demand - ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb6f8bb-d3e1-457c-a482-430e612f90a4",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"./logo.png\">\n",
    "\n",
    "* ref : https://www.kaggle.com/competitions/bike-sharing-demand/data <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11769cb6-b939-495e-96c1-ff3598956cec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container{width:100% !important;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set()\n",
    "\n",
    "#-------------------- 차트 관련 속성 (한글처리, 그리드) -----------\n",
    "plt.rcParams['font.family']= 'Malgun Gothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "#-------------------- 주피터 , 출력결과 넓이 늘리기 ---------------\n",
    "# from IPython.core.display import display, HTML\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(\"<style>.container{width:100% !important;}</style>\"))\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('max_colwidth', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02d88c79-95e1-4b95-96de-df858fcc943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error, make_scorer\n",
    "\n",
    "from sklearn.ensemble     import RandomForestRegressor\n",
    "from sklearn.tree         import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "# ---- 추가 모델\n",
    "from sklearn.ensemble     import AdaBoostRegressor, VotingRegressor\n",
    "from xgboost              import XGBRegressor\n",
    "from lightgbm             import LGBMRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f698b81-6a0b-4c55-b81e-c2fd498d4b74",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aef310ea-ddad-4ad0-bcea-018ebbe0c5d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./train.csv\", parse_dates=['datetime'])\n",
    "test  = pd.read_csv(\"./test.csv\" , parse_dates=['datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23a0bbfd-d222-4822-bfad-0fe563517d46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_list = [train, test]\n",
    "for df in df_list:\n",
    "    df.rename(columns = {'datetime' : 'regdate', 'count' : 'regcount'}, inplace = True)\n",
    "    df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d1e0d4-27a9-4fa8-8d33-d1e7a47e9153",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e56076-05c4-4424-9669-dea75029d881",
   "metadata": {},
   "source": [
    "* 파생피쳐 생성\n",
    "    * regdate -> y, m, d, h, w\n",
    "    * holiday, workingday -> day_type\n",
    "    * h, workingday -> peek\n",
    "    * temp, windspeed -> ideal\n",
    "    * humidity, workingday -> sticky\n",
    "* 자연재해, 공휴일 처리\n",
    "    * Sandy\n",
    "    * Christmas\n",
    "* Outlier 삭제 (train만 해당)\n",
    "    * temp > 40\n",
    "    * windspeed > 50\n",
    "* 연속형 Feature Scaling (logScaling)\n",
    "    * temp, atemp, humidity, windspeed\n",
    "* 다중공선 처리\n",
    "    * temp, atemp  ->  temp\n",
    "    * season, m -> season\n",
    "    * w, day_type, holiday, workingday  -> w, day_type\n",
    "* 이산형 Feature OneHotEncoding\n",
    "    * season, weather, y, h, w, day_type\n",
    "* Target data Scaling (logScaling)\n",
    "* 불필요한 컬럼 삭제\n",
    "    * d, reg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7824002-3887-48c9-97f9-b50bd9862132",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_list = [train, test]\n",
    "df_name = ['train', 'test']\n",
    "for i, df in enumerate(df_list):\n",
    "    # 파생피쳐 생성\n",
    "    df['y'] = df['regdate'].dt.year\n",
    "    df['m'] = df['regdate'].dt.month\n",
    "    df['d'] = df['regdate'].dt.day\n",
    "    df['h'] = df['regdate'].dt.hour\n",
    "    df['w'] = df['regdate'].dt.dayofweek\n",
    "    #df['woy'] = df['regdate'].dt.weekofyear\n",
    "    \n",
    "    df['day_type'] = 0\n",
    "    df['day_type'] = np.where( (df['holiday']==0) & (df['workingday'] == 1),   1,  df['day_type'])\n",
    "    df['day_type'] = np.where( (df['holiday']==1) & (df['workingday'] == 0),   2,  df['day_type'])\n",
    "    \n",
    "    df['peak']   = df[['h', 'workingday']].apply(lambda x: (0, 1)[(x['workingday'] == 1 and  ( x['h'] == 8 or 17 <= x['h'] <= 18 or 12 <= x['h'] <= 12)) or (x['workingday'] == 0 and  10 <= x['h'] <= 19)], axis = 1)\n",
    "    df['ideal']  = df[['temp', 'windspeed']].apply(lambda x: (0, 1)[x['temp'] > 27 and x['windspeed'] < 30], axis = 1)\n",
    "    df['sticky'] = df[['humidity', 'workingday']].apply(lambda x: (0, 1)[x['workingday'] == 1 and x['humidity'] >= 60], axis = 1)\n",
    "    \n",
    "    # 자연재해, sandy\n",
    "    df['holiday'] = df[['m', 'd', 'holiday', 'y']].apply(lambda x: (x['holiday'], 1)[x['y'] == 2012 and x['m'] == 10 and (x['m'] in [30])], axis = 1)\n",
    "    \n",
    "    # 공휴일, christmas day and others\n",
    "    df['holiday'] = df[['m', 'd', 'holiday']].apply(lambda x: (x['holiday'], 1)[x['m'] == 12 and (x['m'] in [24, 26, 31])], axis = 1)\n",
    "    df['workingday'] = df[['m', 'd', 'workingday']].apply(lambda x: (x['workingday'], 0)[x['m'] == 12 and x['m'] in [24, 31]], axis = 1)\n",
    "    \n",
    "    # 불필요한 컬럼 삭제\n",
    "    df.set_index('regdate', inplace=True)\n",
    "    df.drop('d', axis=1, inplace=True)\n",
    "    \n",
    "    # Outlier 삭제 \n",
    "    if df_name[i] == 'train':\n",
    "        del_idx_list = []\n",
    "        # idx = df[df['weather']==4].index\n",
    "        # del_idx_list.extend(idx)\n",
    "        idx = df[df['temp']>40].index\n",
    "        del_idx_list.extend(idx)\n",
    "        idx = df[df['windspeed']>50].index\n",
    "        del_idx_list.extend(idx)\n",
    "        df.drop(del_idx_list, axis=0, inplace=True)\n",
    "    \n",
    "    # 연속형 피쳐 스케일링\n",
    "    df['temp']      = np.log1p( df['temp'] )\n",
    "    df['atemp']     = np.log1p( df['atemp'] )\n",
    "    df['humidity']  = np.log1p( df['humidity'] )\n",
    "    df['windspeed'] = np.log1p( df['windspeed'] )\n",
    "        \n",
    "    # 다중공선 처리\n",
    "    df.drop(['atemp'], axis=1, inplace=True)\n",
    "    df.drop(['m'], axis=1, inplace=True)  # 강사님과 다른점!\n",
    "    df.drop(['holiday', 'workingday'], axis=1, inplace=True)\n",
    "\n",
    "            \n",
    "    # 이산형 피쳐 원핫인코딩\n",
    "    # df = pd.get_dummies(df, columns=['season', 'weather','m', 'y', 'h', 'w', 'day_type'])\n",
    "    df = pd.get_dummies(df, columns=['season', 'weather','y', 'h', 'w', 'day_type'])\n",
    "    \n",
    "    # Target data Scaling\n",
    "    if df_name[i] == 'train':\n",
    "        df['casual'] = np.log1p( df['casual'] )\n",
    "        df['registered'] = np.log1p( df['registered'] )\n",
    "    \n",
    "    globals()[df_name[i]] = df.copy()  #위 코드를 이 블록말고 다른 블록에도 글로벌하게 적용함 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b029fe7-b707-4760-8ebd-b6d3a2e5b91f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## windspeed 0 채우기\n",
    "* 모델 학습을 통해 WindSpeed가 0인 데이터를 채움."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf4d19cc-4b90-40e1-807e-3498347e2643",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE :  0.385180981022705\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([train, test], axis=0, ignore_index=True)\n",
    "\n",
    "target = df[['regcount','casual','registered']]\n",
    "df = df.drop(['regcount','casual','registered'], axis=1)\n",
    "\n",
    "df1   = df[df['windspeed'] != 0]\n",
    "y_df1 = df1['windspeed']\n",
    "X_df1 = df1.drop('windspeed', axis=1)\n",
    "\n",
    "rf = LGBMRegressor(random_state=0)  #RandomForestRegressor(random_state=11)\n",
    "X_df1_8, X_df1_2, y_df1_8, y_df1_2 = train_test_split(X_df1, y_df1, test_size=0.2, random_state=11)\n",
    "rf.fit(X_df1_8, y_df1_8)\n",
    "    \n",
    "pred = rf.predict(X_df1_2)\n",
    "mse_score = mean_squared_error(y_df1_2, pred)\n",
    "print(\"RMSE : \", np.sqrt(mse_score) )\n",
    "\n",
    "df0 = train[train['windspeed'] == 0]\n",
    "widx = df0['windspeed'].index.values\n",
    "X_df0 = df0.drop(['regcount','casual','registered', 'windspeed'], axis=1)\n",
    "pred = rf.predict(X_df0)\n",
    "train.loc[widx, 'windspeed'] = pred\n",
    "    \n",
    "df0 = test[test['windspeed'] == 0]\n",
    "widx = df0['windspeed'].index.values\n",
    "X_df0 = df0.drop('windspeed', axis=1)\n",
    "pred = rf.predict(X_df0)\n",
    "test.loc[widx, 'windspeed'] = pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c516d172-18e6-4c20-a600-c9848bbea7ce",
   "metadata": {},
   "source": [
    "# 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a1c744-f6c5-4551-9ed3-193de936a229",
   "metadata": {},
   "source": [
    "## 기본 모델, Training Score 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb76a413-3251-45d3-96d9-0baf3e8dfa2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def my_fit_score(df, chart_view=False) :\n",
    "    model_list = [ \n",
    "                   (\"RIDGE\"  , Ridge(alpha=1.0, random_state=0)),\n",
    "                   (\"LASSO\"  , Lasso(alpha=1.0, random_state=0)),\n",
    "                   (\"DTR\"    , DecisionTreeRegressor(random_state=0)),\n",
    "                   (\"RF\"     , RandomForestRegressor(random_state=0)),\n",
    "                   (\"LR\"     , LinearRegression()                   ),\n",
    "                   (\"ABOOST\" , AdaBoostRegressor(random_state=0)                  ),\n",
    "                   (\"XGB\"    , XGBRegressor(random_state=0)                       ),   #booster=gblinear\n",
    "                   (\"LGBM\"   , LGBMRegressor(random_state=0)                      ),\n",
    "                   (\"VR-XGB-LGBM\"  , VotingRegressor([(\"XGB\", XGBRegressor(random_state=0)), (\"LGBM\", LGBMRegressor(random_state=0))]) ) ,\n",
    "                   (\"VR-RF-LGBM\"   , VotingRegressor([(\"DTR\", RandomForestRegressor(random_state=0)), (\"LGBM\", LGBMRegressor(random_state=0))]) )\n",
    "                 ]\n",
    "   \n",
    "    y_c = df['casual'] \n",
    "    y_r = df['registered'] \n",
    "\n",
    "    X = df.drop(['regcount','casual','registered'], axis=1)\n",
    "    \n",
    "    for tpl in model_list :\n",
    "        print( tpl[0] ) \n",
    "        model = tpl[1]\n",
    "                \n",
    "        X_train, X_test, y_train, y_r_test = train_test_split(X, y_r, random_state=0, test_size=0.2)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        #------------------------------------------------\n",
    "        # feature_importance 차트 그리기\n",
    "        if bool(chart_view) : \n",
    "            my_view_chart(tpl[0], model, X_train)\n",
    "        #------------------------------------------------\n",
    "        y_r_pred = model.predict(X_test)\n",
    "        \n",
    "        model = tpl[1]\n",
    "        X_train, X_test, y_train, y_c_test = train_test_split(X, y_c, random_state=0, test_size=0.2)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_c_pred = model.predict(X_test)\n",
    "        \n",
    "        #---------(타켓피쳐:로그스케일링) 복원-----------\n",
    "        y_r_pred = np.maximum(0, np.expm1(y_r_pred))\n",
    "        y_c_pred = np.maximum(0, np.expm1(y_c_pred))\n",
    "        \n",
    "        y_r_test = np.maximum(0, np.expm1(y_r_test))\n",
    "        y_c_test = np.maximum(0, np.expm1(y_c_test))\n",
    "        \n",
    "        y_pred_comb = y_r_pred+y_c_pred\n",
    "        y_real_comb = y_r_test+y_c_test\n",
    "        y_pred_comb[y_pred_comb < 0] = 0\n",
    "        \n",
    "        msle_r_score = mean_squared_log_error(y_r_test, y_r_pred)\n",
    "        msle_c_score = mean_squared_log_error(y_c_test, y_c_pred)\n",
    "        msle_score = mean_squared_log_error(y_real_comb, y_pred_comb)\n",
    "    \n",
    "        print(\"registered RMSLE: \", np.sqrt(msle_r_score)) \n",
    "        print(\"casual RMSLE: \", np.sqrt(msle_c_score))\n",
    "        print(\"comb RMSLE: \", np.sqrt(msle_score)) \n",
    "        print(\"-\"*30)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8b7895c-c0da-44f7-949f-2d8f5925e128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RIDGE\n",
      "registered RMSLE:  0.5742291767805591\n",
      "casual RMSLE:  0.5906866100213519\n",
      "comb RMSLE:  0.5458461815870497\n",
      "------------------------------\n",
      "LASSO\n",
      "registered RMSLE:  1.398876371576369\n",
      "casual RMSLE:  1.5097386288234824\n",
      "comb RMSLE:  1.4200361615605412\n",
      "------------------------------\n",
      "DTR\n",
      "registered RMSLE:  0.42700474880878675\n",
      "casual RMSLE:  0.69441530528812\n",
      "comb RMSLE:  0.4070927441120712\n",
      "------------------------------\n",
      "RF\n",
      "registered RMSLE:  0.32270804205557385\n",
      "casual RMSLE:  0.505876772739056\n",
      "comb RMSLE:  0.31366702410923536\n",
      "------------------------------\n",
      "LR\n",
      "registered RMSLE:  0.5751772923617848\n",
      "casual RMSLE:  0.5905920475074817\n",
      "comb RMSLE:  0.5466201991528378\n",
      "------------------------------\n",
      "ABOOST\n",
      "registered RMSLE:  1.0423204145938123\n",
      "casual RMSLE:  0.9714074830825923\n",
      "comb RMSLE:  1.0150184825862532\n",
      "------------------------------\n",
      "XGB\n",
      "registered RMSLE:  0.3169817132234814\n",
      "casual RMSLE:  0.5035251935262637\n",
      "comb RMSLE:  0.30649808359877145\n",
      "------------------------------\n",
      "LGBM\n",
      "registered RMSLE:  0.30928148673800104\n",
      "casual RMSLE:  0.4844661893145207\n",
      "comb RMSLE:  0.30179751948743305\n",
      "------------------------------\n",
      "VR-XGB-LGBM\n",
      "registered RMSLE:  0.30351998364860017\n",
      "casual RMSLE:  0.48215541739023854\n",
      "comb RMSLE:  0.2955627222213018\n",
      "------------------------------\n",
      "VR-RF-LGBM\n",
      "registered RMSLE:  0.30404677199330327\n",
      "casual RMSLE:  0.4806724301476682\n",
      "comb RMSLE:  0.29685163004039644\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "my_fit_score(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f67e0c0-9e17-4257-95fc-bed51d7424f6",
   "metadata": {},
   "source": [
    "## GridSearchCV를 통한 모델 파라메터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90bbedf2-5aec-4723-9708-951b55331eec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def my_scoring(y_true, y_pred):\n",
    "    y_pred = np.expm1(y_pred)\n",
    "    y_true = np.expm1(y_true)\n",
    "    y_pred = np.maximum(0, y_pred)\n",
    "    y_true = np.maximum(0, y_true)\n",
    "    return np.sqrt(mean_squared_log_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3bfd7e4c-b5d8-4c33-8ce9-65d520b53c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_fit_score_cv(df) :\n",
    "    model_list = [ \n",
    "                   (\"RF\"     , RandomForestRegressor(random_state=0)),           \n",
    "                   (\"XGB\"    , XGBRegressor(random_state=0)                       ),   \n",
    "                   (\"LGBM\"   , LGBMRegressor(random_state=0)                      ),\n",
    "                 ]\n",
    "   \n",
    "    mydic = [{'n_estimators':[100, 200], 'min_samples_split':[2, 3], 'min_samples_leaf':[1, 2, 3]},\n",
    "        {'n_estimators':[100, 200, 300], 'learning_rate':[0.1, 0.01, 0.005]},\n",
    "        {'n_estimators':[100, 200, 300], 'learning_rate':[0.1, 0.01, 0.005]}]\n",
    "    \n",
    "    y_c = df['casual'] \n",
    "    y_r = df['registered'] \n",
    "\n",
    "    X = df.drop(['regcount','casual','registered'], axis=1)\n",
    "       \n",
    "    ret_model = []\n",
    "    for i, tpl in enumerate(model_list) :\n",
    "        # print( tpl[0] ) \n",
    "        model = tpl[1]\n",
    "        kf = KFold(n_splits=5, shuffle=True, random_state=11)\n",
    "\n",
    "        models1 = GridSearchCV(model, scoring=make_scorer(my_scoring, greater_is_better=False), param_grid=mydic[i], cv=kf)\n",
    "        models1.fit(X, y_r)\n",
    "        \n",
    "        models2 = GridSearchCV(model, scoring=make_scorer(my_scoring, greater_is_better=False), param_grid=mydic[i], cv=kf)\n",
    "        models2.fit(X, y_c)\n",
    "\n",
    "        ret_model.append((tpl[0], models1, models2))\n",
    "        # print(models1.best_score_, models2.best_score_)\n",
    "        # print(\"-\"*30)\n",
    "        \n",
    "    return ret_model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cdff915-a48d-4b59-9cf0-ead209dd38d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n",
      "registered model best score -0.31313807448880204\n",
      "registered model best parameter {'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "registered model best estimator RandomForestRegressor(min_samples_leaf=2, n_estimators=200, random_state=0)\n",
      "casual model best score -0.5149162648786102\n",
      "casual model best parameter {'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 200}\n",
      "casual model best estimator RandomForestRegressor(min_samples_split=3, n_estimators=200, random_state=0)\n",
      "------------------------------\n",
      "XGB\n",
      "registered model best score -0.30212669491561267\n",
      "registered model best parameter {'learning_rate': 0.1, 'n_estimators': 300}\n",
      "registered model best estimator XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=0, ...)\n",
      "casual model best score -0.5052762722396908\n",
      "casual model best parameter {'learning_rate': 0.1, 'n_estimators': 300}\n",
      "casual model best estimator XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             n_estimators=300, n_jobs=None, num_parallel_tree=None,\n",
      "             predictor=None, random_state=0, ...)\n",
      "------------------------------\n",
      "LGBM\n",
      "registered model best score -0.2918830304577625\n",
      "registered model best parameter {'learning_rate': 0.1, 'n_estimators': 300}\n",
      "registered model best estimator LGBMRegressor(n_estimators=300, random_state=0)\n",
      "casual model best score -0.4932228076490093\n",
      "casual model best parameter {'learning_rate': 0.1, 'n_estimators': 300}\n",
      "casual model best estimator LGBMRegressor(n_estimators=300, random_state=0)\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "models = my_fit_score_cv(train)\n",
    "\n",
    "for m in models:\n",
    "    print(m[0])\n",
    "    print(\"registered model best score\", m[1].best_score_)\n",
    "    print(\"registered model best parameter\", m[1].best_params_)\n",
    "    print(\"registered model best estimator\", m[1].best_estimator_)\n",
    "    print(\"casual model best score\", m[2].best_score_)\n",
    "    print(\"casual model best parameter\", m[2].best_params_)\n",
    "    print(\"casual model best estimator\", m[2].best_estimator_)\n",
    "    print(\"-\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77c8815-a400-4774-bf01-3e4f789b9a60",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 점수보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61b5863-2ecb-4937-833c-df0181cd78f0",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09e23d8f-07a6-4b3c-a163-c18f722eb642",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = models[0][1].predict(test)\n",
    "y_pred2 = models[0][2].predict(test)\n",
    "\n",
    "result = pd.read_csv('./sampleSubmission.csv')\n",
    "result['count'] = np.expm1(y_pred1)+np.expm1(y_pred2)\n",
    "\n",
    "result.to_csv('./submit_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c19a89-caaf-4356-887e-bb51a7902aee",
   "metadata": {},
   "source": [
    "## XGB Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b7f84e5-dda3-4ca0-86f8-bb52f97c6ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = models[1][1].predict(test)\n",
    "y_pred2 = models[1][2].predict(test)\n",
    "\n",
    "result = pd.read_csv('./sampleSubmission.csv')\n",
    "cnt_result  = np.expm1(y_pred1)+np.expm1(y_pred2)\n",
    "result['count'] = np.maximum(0, cnt_result)\n",
    "\n",
    "result.to_csv('./submit_xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1598d82f-803d-4d71-b5d5-05584c015b4e",
   "metadata": {},
   "source": [
    "## LGBM Moel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5acc78af-a3f8-4d35-b327-c6c2a7674d0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred1 = models[2][1].predict(test)\n",
    "y_pred2 = models[2][2].predict(test)\n",
    "\n",
    "result = pd.read_csv('./sampleSubmission.csv')\n",
    "result['count'] = np.expm1(y_pred1)+np.expm1(y_pred2)\n",
    "\n",
    "result.to_csv('./submit_lgbm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe69d35-8f07-46fd-b9fc-f508920ac5f0",
   "metadata": {},
   "source": [
    "## Voing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18e3cc4f-4168-4ce0-9d31-9246fd41b421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VotingRegressor만 따로 fit predict\n",
    "model1= VotingRegressor([(\"XGB\", XGBRegressor(n_estimators=300, learning_rate=0.01, random_state=0)), \n",
    "                         (\"LGBM\", LGBMRegressor(n_estimators=300, learning_rate=0.01, random_state=0))]) \n",
    "model2= VotingRegressor([(\"XGB\", XGBRegressor(random_state=0)), \n",
    "                         (\"LGBM\", LGBMRegressor(n_estimators=200, random_state=0))]) \n",
    "\n",
    "y_c = train['casual'] \n",
    "y_r = train['registered'] \n",
    "\n",
    "X = train.drop(['regcount','casual','registered'], axis=1)\n",
    "\n",
    "model1.fit(X, y_c)\n",
    "model2.fit(X, y_r)\n",
    "\n",
    "y_pred1 = model1.predict(test)\n",
    "y_pred2 = model2.predict(test)\n",
    "\n",
    "result = pd.read_csv('./sampleSubmission.csv')\n",
    "cnt_result  = np.expm1(y_pred1)+np.expm1(y_pred2)\n",
    "result['count'] = np.maximum(0, cnt_result)\n",
    "result.to_csv('./submit_vt.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560e1a3e-86b9-4be6-9072-fa802e51d5c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
